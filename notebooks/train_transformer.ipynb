{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<a href=\"https://colab.research.google.com/github/nmach22/Promoter-Classification/blob/main/notebooks/train_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>",
   "id": "e8c7e1690c17c7bd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Set Env**",
   "id": "dcb183911830b65f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%%capture\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "from google.colab import userdata\n",
    "token = userdata.get('GITHUB_TOKEN')\n",
    "user_name = userdata.get('GITHUB_USERNAME')\n",
    "mail = userdata.get('GITHUB_MAIL')\n",
    "\n",
    "!git config --global user.name \"{user_name}\"\n",
    "!git config --global user.email \"{mail}\"\n",
    "!git clone https://{token}@github.com/nmach22/Promoter-Classification.git\n",
    "!pip install -r ./Promoter-Classification/requirements.txt\n"
   ],
   "id": "f936bd54efed7f28"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Imports**",
   "id": "855b2fd262158271"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import random_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the root directory of the cloned repository to the Python path\n",
    "ROOT_DIR = '/content/Promoter-Classification'\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "\n",
    "import importlib\n",
    "import utils.fasta_dataset as dataset_module\n",
    "import utils.encoding_functions as encoding_module\n",
    "import utils.data_split as splitter_module\n",
    "import models.transformer as transformer_module\n",
    "import utils.train as train_module\n",
    "import eval.train_evals as eval_module\n",
    "import eval.metrics as metrics_module\n",
    "importlib.reload(dataset_module)\n",
    "importlib.reload(encoding_module)\n",
    "importlib.reload(transformer_module)\n",
    "importlib.reload(train_module)\n",
    "importlib.reload(eval_module)\n",
    "importlib.reload(metrics_module)\n",
    "from utils.fasta_dataset import FastaDataset\n",
    "from utils.encoding_functions import *\n",
    "from models.transformer import DNATransformer\n",
    "from utils.data_split import dataset_split\n",
    "from utils.train import Train\n",
    "from eval.train_evals import TrainEvals\n",
    "from eval.metrics import *\n",
    "\n",
    "with open(f\"{ROOT_DIR}/config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(config.keys())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "142590e7d7bea7c3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Read Data**",
   "id": "2e24d6817d0e20ee"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "ecoli_data = config['data']['bacillus']\n",
    "\n",
    "prom_path = f\"{ROOT_DIR}/{ecoli_data['promoter_fasta']}\"\n",
    "non_prom_path = f\"{ROOT_DIR}/{ecoli_data['non_promoter_fasta']}\"\n",
    "seq_length = ecoli_data['seq_len']\n",
    "\n",
    "dataset = FastaDataset(prom_path, non_prom_path, seq_len=seq_length,encoding_func=token_encode)"
   ],
   "id": "2f2922670a57f015"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Split Data**",
   "id": "fae223a1926a2fb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_dataset, val_dataset, test_dataset = dataset_split(dataset)",
   "id": "e495da2523df21cb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Dataset Visualization**",
   "id": "410e1d9d8d3499a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "save_dir = f\"/content/drive/MyDrive/checkpoints_bio/transformer/{ecoli_data['name']}\"",
   "id": "7fdf6240917de957"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "labels = [dataset[i][1].item() for i in range(len(train_dataset))]\n",
    "label_counts = pd.Series(labels).value_counts().sort_index()\n",
    "label_counts\n",
    "\n",
    "# label_counts.index = ['Non-Promoter', 'Promoter']\n",
    "\n",
    "# plt.figure(figsize=(6, 4))\n",
    "# sns.barplot(x=label_counts.index, y=label_counts.values, palette=['skyblue', 'salmon'])\n",
    "# plt.title(f'Class Distribution in {ecoli_data[\"name\"]} Dataset')\n",
    "# plt.ylabel('Count')\n",
    "\n",
    "# os.makedirs(save_dir, exist_ok=True)\n",
    "# save_path = os.path.join(save_dir, \"class_dist\")\n",
    "# plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Class Distribution:\")\n",
    "# print(label_counts)"
   ],
   "id": "ebc3cce033006b94"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Create Data Loaders**",
   "id": "881fdca92c7a193d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "batch_size = config['train']['batch_size']\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "id": "b4403d3932e091d9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Train Model**",
   "id": "72aa7ded6406ebc9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = DNATransformer(seq_length,nhead=2,num_layers=1,dropout=0.1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "train = Train(model, train_loader,val_loader,optimizer,criterion,[TrainEvals()],device)\n",
    "train.train(100,True)"
   ],
   "id": "94089be4f9505584"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# **Evaluation**",
   "id": "b31406e9c4615fe0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "fpr, tpr, roc_auc, all_labels, all_predictions = calculate_roc_data(model,test_loader,False,device)",
   "id": "97f4e9e3c01666d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plot_roc_curve(fpr, tpr, roc_auc,save_dir=save_dir,\n",
    "                file_name='bacillus_roc_curve'\n",
    "               )"
   ],
   "id": "73b6bafe3d745429"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "thresholds = np.linspace(0, 1, 100)\n",
    "\n",
    "# Call the function to find the optimal threshold\n",
    "optimal_threshold, max_f1_score = find_optimal_threshold(all_labels, all_predictions, thresholds)\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")\n",
    "print(f\"Maximum F1-score at optimal threshold: {max_f1_score:.4f}\")"
   ],
   "id": "887c70377063c8ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Assuming optimal_threshold is already defined or will be defined next\n",
    "# For now, let's plot with a default 0.5 or the previously calculated optimal_threshold if it exists\n",
    "plot_confusion_matrix(all_labels, all_predictions, threshold=optimal_threshold, title='Confusion Matrix with Optimal Threshold',\n",
    "                      save_dir=save_dir,\n",
    "                      file_name='bacillus_confusion_matrix'\n",
    "                      )"
   ],
   "id": "d868dce9d4b7fbd1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Call the function to calculate and print metrics using the optimal_threshold\n",
    "metrics_dict = calculate_metrics(all_labels, all_predictions, optimal_threshold)\n",
    "\n",
    "print(f\"Metrics at Optimal Threshold ({optimal_threshold:.4f}):\")\n",
    "for metric_name, value in metrics_dict.items():\n",
    "    print(f\"  {metric_name}: {value:.4f}\")"
   ],
   "id": "f207a998dfeb9e44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "seq = dataset.sequences[0]\n",
    "\n",
    "kmers = random_substitution_top_kmers(\n",
    "    model,\n",
    "    seq,\n",
    "    encoding_func=token_encode,\n",
    "    seq_len=81,\n",
    "    window_size=7,\n",
    "    top_k=10,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "for pos, kmer, score in kmers:\n",
    "    print(f\"Position {pos}: {kmer}  (importance={score:.4f})\")"
   ],
   "id": "51656088f13449e1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "json_file_name = \"bacillus_json\"\n",
    "\n",
    "# Prepare kmer data for JSON serialization (convert numpy types to native Python types)\n",
    "kmer_data = [\n",
    "    {\n",
    "        \"position\": int(pos),\n",
    "        \"kmer\": kmer,\n",
    "        \"importance\": float(score)\n",
    "    }\n",
    "    for pos, kmer, score in kmers\n",
    "]\n",
    "\n",
    "# Prepare metrics data for JSON serialization (convert numpy types to native Python types)\n",
    "# Ensure all values in metrics_dict are native Python types\n",
    "metrics_serializable = {\n",
    "    key: float(value) if isinstance(value, np.floating) else value\n",
    "    for key, value in metrics_dict.items()\n",
    "}\n",
    "\n",
    "# Combine all data into a single dictionary\n",
    "output_data = {\n",
    "    \"top_kmers\": kmer_data,\n",
    "    \"metrics\": metrics_serializable\n",
    "}\n",
    "\n",
    "# Define the full path for the JSON file\n",
    "json_file_path = os.path.join(save_dir, f\"{json_file_name}.json\")\n",
    "\n",
    "# Save the data to a JSON file\n",
    "with open(json_file_path, 'w') as f:\n",
    "    json.dump(output_data, f, indent=4)\n",
    "\n",
    "print(f\"Successfully saved top kmers and metrics to {json_file_path}\")"
   ],
   "id": "1640415c243d9aa5"
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
