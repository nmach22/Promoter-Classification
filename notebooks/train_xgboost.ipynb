{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmach22/Promoter-Classification/blob/main/notebooks/train_xgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-header"
      },
      "source": [
        "# **Set Env**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup-code"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import shutil\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "REPO_PATH = '/content/drive/MyDrive/Promoter-Classification'\n",
        "REPO_URL = \"https://github.com/nmach22/Promoter-Classification.git\"\n",
        "\n",
        "# 1. Delete repo if it already exists (Ensure fresh code)\n",
        "if os.path.exists(REPO_PATH):\n",
        "    print(f\"Deleting existing repository at {REPO_PATH}...\")\n",
        "    shutil.rmtree(REPO_PATH)\n",
        "\n",
        "# 2. Clone repository\n",
        "os.chdir('/content/drive/MyDrive')\n",
        "print(f\"Cloning repository to {REPO_PATH}...\")\n",
        "!git clone {REPO_URL}\n",
        "\n",
        "# 3. Enter the repository\n",
        "os.chdir(REPO_PATH)\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# 4. Add source code to Python path\n",
        "sys.path.append(REPO_PATH)\n",
        "\n",
        "# 5. Install requirements\n",
        "!pip install -r requirements.txt\n",
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imports-header"
      },
      "source": [
        "# **Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports-code"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import yaml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, matthews_corrcoef, classification_report, roc_curve, auc\n",
        "from Bio import SeqIO\n",
        "import importlib\n",
        "\n",
        "# Set ROOT_DIR to the current working directory (which is REPO_PATH set in previous cell)\n",
        "ROOT_DIR = os.getcwd()\n",
        "if ROOT_DIR not in sys.path:\n",
        "    sys.path.append(ROOT_DIR)\n",
        "\n",
        "import utils.fasta_dataset as dataset_module\n",
        "import utils.encoding_functions as encoding_module\n",
        "import utils.data_split as splitter_module\n",
        "import models.xgboost_model as xgboost_module\n",
        "\n",
        "importlib.reload(encoding_module)\n",
        "importlib.reload(xgboost_module)\n",
        "\n",
        "from utils.fasta_dataset import FastaDataset\n",
        "from utils.encoding_functions import one_hot_encode, flatten_one_hot_encode, kmer_encode\n",
        "from utils.data_split import dataset_split\n",
        "from models.xgboost_model import XGBoostPromoterModel\n",
        "\n",
        "with open(f\"{ROOT_DIR}/config/config.yaml\", \"r\") as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "print(\"Config loaded.\")\n",
        "print(\"Device: CPU (XGBoost)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feature-eng-header"
      },
      "source": [
        "# **Feature Engineering**\n",
        "\n",
        "XGBoost requires numerical input. We will use two types of features:\n",
        "1. **Flattened One-Hot Encoding**: Preserves positional information (critical for promoter motifs like TATA box at specific locations).\n",
        "2. **K-mer Counts**: Captures frequency of short subsequences (e.g., 3-mers)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "feature-eng-code"
      },
      "outputs": [],
      "source": [
        "# We use functions from utils.encoding_functions\n",
        "# flatten_one_hot_encode(seq, max_seq_len)\n",
        "# kmer_encode(seq, seq_len, k=3)\n",
        "\n",
        "def combined_features(seq, max_seq_len, k=3):\n",
        "    \"\"\"\n",
        "    Combines flattened one-hot and k-mer counts.\n",
        "    \"\"\"\n",
        "    one_hot = flatten_one_hot_encode(seq, max_seq_len)\n",
        "    # kmers = kmer_encode(seq, max_seq_len, k=k) # Uncomment to add k-mers\n",
        "    # return np.concatenate([one_hot, kmers])\n",
        "    return one_hot # Start with one-hot as primary feature\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "data-load-header"
      },
      "source": [
        "# **Read & Prepare Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "data-load-code"
      },
      "outputs": [],
      "source": [
        "# Select Dataset (e.g., E. coli)\n",
        "dataset_key = 'arabidopsis_tata' # Change this to 'human_tata', 'mouse_tata', etc.\n",
        "data_config = config['data'][dataset_key]\n",
        "prom_path = f\"{ROOT_DIR}/{data_config['promoter_fasta']}\"\n",
        "non_prom_path = f\"{ROOT_DIR}/{data_config['non_promoter_fasta']}\"\n",
        "seq_length = data_config['seq_len']\n",
        "\n",
        "print(f\"Using dataset: {data_config['name']}\")\n",
        "print(f\"Promoter file: {prom_path}\")\n",
        "print(f\"Non-promoter file: {non_prom_path}\")\n",
        "\n",
        "# Use FastaDataset\n",
        "dataset = FastaDataset(\n",
        "    prom_path, \n",
        "    non_prom_path, \n",
        "    seq_len=seq_length, \n",
        "    encoding_func=lambda s, l: combined_features(s, l)\n",
        ")\n",
        "\n",
        "print(f\"Total samples: {len(dataset)}\")\n",
        "print(f\"Feature vector shape: {dataset[0][0].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vis-data-header"
      },
      "source": [
        "# **Dataset Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vis-data-code"
      },
      "outputs": [],
      "source": [
        "labels = [dataset[i][1].item() for i in range(len(dataset))]\n",
        "label_counts = pd.Series(labels).value_counts().sort_index()\n",
        "label_counts.index = ['Non-Promoter', 'Promoter']\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=label_counts.index, y=label_counts.values, palette=['skyblue', 'salmon'])\n",
        "plt.title(f'Class Distribution in {data_config[\"name\"]} Dataset')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "print(\"Class Distribution:\")\n",
        "print(label_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "split-data-header"
      },
      "source": [
        "# **Split Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "split-data-code"
      },
      "outputs": [],
      "source": [
        "train_subset, val_subset, test_subset = dataset_split(dataset)\n",
        "\n",
        "def subset_to_numpy(subset):\n",
        "    \"\"\"\n",
        "    Converts a PyTorch Subset to numpy arrays (X, y).\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(subset)):\n",
        "        sample_x, sample_y = subset[i]\n",
        "        X.append(sample_x.numpy())\n",
        "        y.append(sample_y.item())\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "print(\"Converting datasets to numpy arrays for XGBoost...\")\n",
        "X_train, y_train = subset_to_numpy(train_subset)\n",
        "X_val, y_val = subset_to_numpy(val_subset)\n",
        "X_test, y_test = subset_to_numpy(test_subset)\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Val shape: {X_val.shape}, {y_val.shape}\")\n",
        "print(f\"Test shape: {X_test.shape}, {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-header"
      },
      "source": [
        "# **Train XGBoost Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-code"
      },
      "outputs": [],
      "source": [
        "# Calculate scale_pos_weight to handle class imbalance\n",
        "num_neg = len(y_train) - sum(y_train)\n",
        "num_pos = sum(y_train)\n",
        "scale_weight = num_neg / num_pos\n",
        "\n",
        "print(f\"Class Imbalance - Negatives: {num_neg}, Positives: {num_pos}\")\n",
        "print(f\"Using scale_pos_weight: {scale_weight:.2f}\")\n",
        "\n",
        "# Initialize model with class weight\n",
        "model = XGBoostPromoterModel(\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    scale_pos_weight=scale_weight # Give more weight to promoters\n",
        ")\n",
        "\n",
        "# Train and capture logs\n",
        "print(\"Training...\")\n",
        "evals_result = {}\n",
        "model.model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "    verbose=50\n",
        ")\n",
        "\n",
        "# Retrieve results manually if using wrapper or access underlying model\n",
        "results = model.model.evals_result()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-curve-header"
      },
      "source": [
        "# **Training Curves**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train-curve-code"
      },
      "outputs": [],
      "source": [
        "epochs = len(results['validation_0']['logloss'])\n",
        "x_axis = range(0, epochs)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(x_axis, results['validation_0']['logloss'], label='Train')\n",
        "ax.plot(x_axis, results['validation_1']['logloss'], label='Validation')\n",
        "ax.legend()\n",
        "plt.ylabel('Log Loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.title('XGBoost Log Loss')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eval-header"
      },
      "source": [
        "# **Evaluation**\n",
        "\n",
        "Metrics from paper:\n",
        "- **Sn (Sensitivity)**: Recall\n",
        "- **Sp (Specificity)**: True Negative Rate\n",
        "- **CC**: Matthews Correlation Coefficient\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eval-code"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    \n",
        "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    mcc = matthews_corrcoef(y_true, y_pred)\n",
        "    \n",
        "    return {\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Sensitivity (Sn)\": sensitivity,\n",
        "        \"Specificity (Sp)\": specificity,\n",
        "        \"CC (MCC)\": mcc,\n",
        "        \"Confusion Matrix\": cm\n",
        "    }\n",
        "\n",
        "# Try different thresholds\n",
        "thresholds = [0.3, 0.4, 0.5]\n",
        "for t in thresholds:\n",
        "    print(f\"\\n--- Threshold: {t} ---\")\n",
        "    y_pred = model.predict(X_test, threshold=t)\n",
        "    metrics = calculate_metrics(y_test, y_pred)\n",
        "    for k, v in metrics.items():\n",
        "        if k != \"Confusion Matrix\":\n",
        "            print(f\"{k}: {v:.4f}\")\n",
        "\n",
        "# Use best threshold for plots (e.g. 0.4)\n",
        "best_threshold = 0.4\n",
        "y_pred = model.predict(X_test, threshold=best_threshold)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "metrics = calculate_metrics(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vis-header"
      },
      "source": [
        "# **Visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vis-code"
      },
      "outputs": [],
      "source": [
        "# 1. Confusion Matrix Heatmap\n",
        "plt.figure(figsize=(6, 5))\n",
        "cm = metrics[\"Confusion Matrix\"]\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Promoter', 'Promoter'], yticklabels=['Non-Promoter', 'Promoter'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title(f'Confusion Matrix (Threshold={best_threshold})')\n",
        "plt.show()\n",
        "\n",
        "# 2. ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Feature Importance (Top 20)\n",
        "importance = model.model.feature_importances_\n",
        "indices = np.argsort(importance)[-20:]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.title('Top 20 Feature Importances')\n",
        "plt.barh(range(len(indices)), importance[indices], color='b', align='center')\n",
        "plt.yticks(range(len(indices)), indices)\n",
        "plt.xlabel('Relative Importance')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "save-header"
      },
      "source": [
        "# **Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save-code"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "save_dir = f\"{ROOT_DIR}/models/\"\n",
        "if not os.path.exists(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "\n",
        "save_path = f\"{save_dir}/xgboost_model.json\"\n",
        "model.save_model(save_path)\n",
        "print(f\"Model saved to {save_path}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
